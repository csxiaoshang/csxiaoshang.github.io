---
title: 暑期实习面试准备
date: 2020-02-17 16:36:25
categories: note
tags: interview
---

### 数据结构和算法

- 红黑树
- B树和B+树
- 大文件排序
[对含有一亿数据的大文件进行排序，要求使用内存小于32MB](https://blog.csdn.net/qq_29048719/article/details/81133643)
参考链接：
[二叉树，平衡二叉树，红黑树，B-树、B+树、B*树的区别](https://blog.csdn.net/wyqwilliam/article/details/82935922)
[红黑树和AVL树（平衡二叉树）区别](https://blog.csdn.net/u010899985/article/details/80981053#commentBox)
[一步步分析为什么B+树适合作为索引的结构 以及索引原理 (阿里面试)](https://www.cnblogs.com/aspirant/p/9214485.html)
### Java基础
[面向对象与面向过程的优缺点](https://www.cnblogs.com/nanqiang/p/9934063.html)
[面向对象五大基本原则详解](https://blog.csdn.net/qq_34375473/article/details/84852650)
[反射原理](https://blog.csdn.net/h2604396739/article/details/83109292)
[补码原理——负数为什么要用补码表示](https://blog.csdn.net/leonliu06/article/details/78685197)
<!--more-->
### Jvm

- 分代回收算法:http://www.importnew.com/19255.html
年轻代：复制回收算法 Scavenge GC（Eden->Survivor->Survivor）
老年代：年轻代n次回收后，扔存在的对象进入老年代。Full GC（老年、持久被写满或显示调用）用的是标记／清除法，老年代的垃圾回收会导致长时间的停顿
持久代：存放静态文件
收集器：串行：单线程效率高（适用于client模式下）；并行：多线程（最大垃圾回收暂停:吞吐量）；并发：应用不停止，响应要求高。浮动垃圾，需要保证内存空间
CMS收集器，目前web服务器开发最常用的收集器，并发收集（也就是垃圾回收线程和应用程序线程同时运行）。问豪神：（由于这个阶段应用程序同时也在运行，所以并发标记阶段结束后，并不能标记出所有的存活对象。为了解决这个问题，需要再次停顿应用程序，称为 再次标记阶段（remark））

- 在Java语言中，可以作为GC Roots的对象包括下面几种：

虚拟机栈（栈帧中的本地变量表）中的引用对象。
方法区中的类静态属性引用的对象。
方法区中的常量引用的对象。
本地方法栈中JNI（Native方法）的引用对象

- JVM垃圾收集器：
  Serial 收集器：串行收集器，使用单线程进行收集，适用于client模式
  ParNew收集器：Serial的多线程版本
  CMS 收集器：
  初始标记：只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿
  并发标记：进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿
  重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿
  并发清除：不需要停顿
- 对象创建过程：
检查常量池中是否有即将要创建的这个对象所属的类的符号引用；
进而检查这个符号引用所代表的类是否已经被JVM加载；若该类还没有被加载，就找该类的class文件，并加载进方法区；若该类已经被JVM加载，则准备为对象分配内存；
根据方法区中该类的信息确定该类所需的内存大小； 一个对象所需的内存大小是在这个对象所属类被定义完就能确定的！且一个类所生产的所有对象的内存大小是一样的！JVM在一个类被加载进方法区的时候就知道该类生产的每一个对象所需要的内存大小。
从堆中划分一块对应大小的内存空间给新的对象； 分配堆中内存有两种方式：指针碰撞 －－如果JVM的垃圾收集器采用复制算法或标记-整理算法，那么堆中空闲内存是完整的区域，并且空闲内存和已使用内存之间由一个指针标记。那么当为一个对象分配内存时，只需移动指针即可。因此，这种在完整空闲区域上通过移动指针来分配内存的方式就叫做“指针碰撞”。　　空闲列表 －－如果JVM的垃圾收集器采用标记-清除算法，那么堆中空闲区域和已使用区域交错，因此需要用一张“空闲列表”来记录堆中哪些区域是空闲区域，从而在创建对象的时候根据这张“空闲列表”找到空闲区域，并分配内存。
为对象中的成员变量赋上初始值(默认初始化)；对于同时被static和final修饰的常量，必须在声明的时候就为其显式地赋值，否则编译时不通过；
设置对象头中的信息；
调用对象的构造函数进行初始化
- JVM内存模型：
【Java堆】用于存储Java对象，每个Java对象都是这个对象类的副本，会复制包含继承自它父类的所有非静态属性。
【方法区】用于存储类结构信息，class文件加载进JVM时会被解析成JVM识别的几个部分分别存储在不同的数据结构中：常量池、域、方法数据、方法体、构造函数，包括类中的方法、实例初始化、接口初始化等。
【Java栈】和线程关联，每个线程创建的时候，JVM都会为他分配一个对应的Java栈，这个栈含有多个栈帧；栈帧则是个方法关联，每个方法的运行都会创建一个自己的栈帧，含有内存变量，操作栈、方法返回值。
【PC寄存器】则用于记录下一条要执行的字节码指令地址和被中断。如果方法是 native的，程序计数器寄存器的值不会被定义为空。
【本地方法栈】是为JVM运行Native方法准备的空间，类似于Java栈。

- 双亲委派模型

启动类加载器  拓展类加载器  应用程序类加载器 自定义加载器
每个类加载器在收到类加载请求时，都不会自己先加载，而是将该请求委派给父类加载器去完成，若父类加载器可以完成该类的加载请求任务，
则成功返回，若父类加载器无法完成该类的加载请求任务，子类加载器才会尝试加载，这就是双亲委派模式。

优点：采用双亲委派模式可使Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关系可以避免类的重复加载，当父加载器已经加载了该类时，就没有必要让子ClassLoader再加载一次。其次还可以防止子类加载器加载的类恶意覆盖Java核心API。例如，类java.lang.Object类存放在JDK\jre\lib下的rt.jar之中，因此无论是哪个类加载器要加载此类，最终都会委派给启动类加载器进行加载，这边保证了Object类在程序中的各种类加载器中都是同一个类。即使两个类来源于同一个Class文件，只要加载它们的类加载器不同，那这两个类就必定不相等。

- 类加载

启动类加载器：Bootstrap ClassLoader，它负责加载存放在JDK\jre\lib(JDK代表??JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库（如rt.jar，所有的java.*开头的类均被Bootstrap ClassLoader加载）。启动类加载器是无法被Java程序直接引用的。
扩展类加载器：Extension ClassLoader，该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载JDK\jre\lib\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库（如javax.*开头的类），开发者可以直接使用扩展类加载器。
应用程序类加载器：Application ClassLoader，该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径（ClassPath）所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。
因为JVM自带的ClassLoader只是懂得从本地文件系统加载标准的java class文件，因此如果编写了自己的ClassLoader，便可以做到如下几点：1）在执行非置信代码之前，自动验证数字签名。2）动态地创建符合用户特定需要的定制化构建类。3）从特定的场所取得java class，例如数据库中和网络中。

- 符号引用和直接引用

在java中，一个java类将会编译成一个class文件。在编译时，java类并不知道引用类的实际内存地址，因此只能使用符号引用来代替。比如org.simple.People类引用org.simple.Tool类，在编译时People类并不知道Tool类的实际内存地址，因此只能使用符号org.simple.Tool(假设)来表示Tool类的地址。而在类装载器装载People类时，此时可以通过虚拟机获取Tool类 的实际内存地址，因此便可以既将符号org.simple.Tool替换为Tool类的实际内存地址，及直接引用地址。
符号引用：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到了内存中。
直接引用：直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是与虚拟机实现的内存布局相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那说明引用的目标必定已经存在于内存之中了。

参考链接：
[深入理解JVM虚拟机2：JVM垃圾回收基本原理和算法](https://blog.csdn.net/a724888/article/details/77981592)
[CMS收集器和G1收集器 他们的优缺点对比 最后并发清除 CMS 不需要停顿，G1需要停顿...](https://blog.csdn.net/diaopai5230/article/details/101216653)
[Jvm介绍](https://thinkinjava.cn/categories/JVM/)
[自定义类加载器](https://blog.csdn.net/qq_36071795/article/details/83715456)
[java虚拟机的符号引用和直接引用](https://blog.csdn.net/qq_34402394/article/details/72793119#commentBox)
[JVM关于OOM异常的调优](https://blog.csdn.net/seujava_er/article/details/90114716)
[深入理解 Tomcat（四）Tomcat 类加载器之为何违背双亲委派模型](https://blog.csdn.net/qq_38182963/article/details/78660779)
### 并发

    1.悲观锁：比较适合写入操作比较频繁的场景，如果出现大量的读取操作，每次读取的时候都会进行加锁，这样会增加大量的锁的开销，降低了系统的吞吐量。
    2.乐观锁：比较适合读取操作比较频繁的场景，如果出现大量的写入操作，数据发生冲突的可能性就会增大，为了保证数据的一致性，应用层需要不断的重新获取数据，这样会增加大量的查询操作，降低了系统的吞吐量。
    3.线程池：新建线程 -> 达到核心数 -> 加入队列 -> 新建线程（非核心） -> 达到最大数 -> 触发拒绝策略。　线程数量未达到corePoolSize，则新建一个线程(核心线程)执行任务。线程数量达到了corePools，则将任务移入队列。等待队列已满，新建线程(非核心线程)执行任务。队列已满，总线程数又达到了maximumPoolSize，就会由(RejectedExecutionHandler)抛出异常
    4.为什么使用线程池：单个任务处理时间比较短，需要处理的任务数量很大。降低资源消耗　提高线程的可管理性　
    5.newCachedThreadPool 工作线程的创建数量几乎没有限制 newFixedThreadPool　　　 newScheduledThreadPool支持定时及周期性任务执行　　newSingleThreadExecutor单线程化的线程池，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行　　　
    6.线程池中的线程在新建后进入while循环，从task队列获取任务，当没有待执行任务时，若线程数量小于等于核心线程数量，若核心线程不可退出则调用队列的take阻塞直到新任务到来，若可以退出，则调用poll，时间超时后线程结束。
    7.CountDownLatch 利用它可以实现一个任务等待其他一个或一组任务执行后再触发的功能，不可重用。CyclicBarrier　让一组线程等待至某个状态之后再全部同时执行，可重用。
    8.分布式系统CAP定理：Consistency（一致性），Availability（可用性），Partition tolerance（分区容错）　web场景一般可用性高于一致性　所以退而求其次追求最终一致性(eventual consistency)　　分区容错在分布式系统中不可避免
    9.自旋锁与互斥锁：自旋锁不会引起调用者睡眠，如果自旋锁已经被别的执行单元保持，调用者就一直循环在那里看是 否该自旋锁的保持者已经释放了锁，所以自旋锁的效率远 高于互斥锁。虽然它的效率比互斥锁高，但是它一直占用CPU，他在未获得锁的情况下，一直运行－－自旋，所以占用着CPU，如果不能在很短的时间内获得锁，这无疑会使CPU效率降低。不适用与IO场景，单核CPU，代码长时间执行。自旋锁的实现：使用java的cas原子操作AtomicReference，循环将原子变量从null设置为当前线程，若当前原子变量不为null则一直循环。
    10.死锁的原因与预防：１互斥：某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程　２占有且等待：一个进程本身占有资源（一种或多种），同时还有资源未得到满足，正在等待其他进程释放该资源　３不可抢占：别人已经占有了某项资源，你不能因为自己也需要该资源，就去把别人的资源抢过来。　４循环等待：存在一个进程环，使得每个进程都占有下一个进程所需的至少一种资源。
       预防的主要做法是破坏除互斥之外的三个条件
    11.线程与进程的区别：
       一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程是操作系统可识别的最小执行和调度单位。
       资源分配给进程，同一进程的所有线程共享该进程的所有资源。 同一进程中的多个线程共享代码段(代码和常量)，数据段(全局变量和静态变量)，扩展段(堆存储)。但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。
       引入线程的操作系统中，把线程作为调度和分派的基本单位。而把进程作为资源拥有的基本单位
       系统开销　由于在创建或撤消进程时，系统都要为之分配或回收资源，如内存空间、I／o设备等。因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。
    12.进程的几种状态: 1) 运行状态：进程正在处理器上上运行。在单处理器环境下，每个时刻最多只有一个进程处于运行状态。2) 就绪状态：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器即可运行。3) 阻塞状态：又称为等待状态，进程正在等待某一事件而暂停运行，如等待某资源为可用（不包括处理器）或等待输入/输出完成。即使处理器空闲，该进程也不能运行。4) 创建状态：进程正在被创建，尚未到就绪状态。5) 结束状态：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。
    13.程序段(Text):程序代码在内存中的映射，存放函数体的二进制代码。初始化过的数据(Data):在程序运行初已经对变量进行初始化的数据。未初始化过的数据(BSS):在程序运行初未对变量进行初始化的数据。栈 (Stack):存储局部、临时变量，函数调用时，存储函数的返回指针，用于控制函数的调用和返回。在程序块开始时自动分配内存,结束时自动释放内存，其操作方式类似于数据结构中的栈。堆 (Heap):存储动态内存分配,需要程序员手工分配,手工释放.
    14.使用线程池的好处：减少创建和销毁线程导致的时间开销和内存资源开销，如果不使用线程池可能导致系统创建大量同类线程导致资源耗尽或者频繁切换
    15.UUID含义是通用唯一识别码 (Universally Unique Identifier) UUID由以下几部分的组合：
       1）当前日期和时间，UUID的第一个部分与时间有关，如果你在生成一个UUID之后，过几秒又生成一个UUID，则第一个部分不同，其余相同
       2）时钟序列。？？？问五七
       3）全局唯一的IEEE机器识别号，如果有网卡，从网卡MAC地址获得，没有网卡以其他方式获得
    16.线程的几种创建方式：以继承Thread类的方式创建线程，　以实现Runnable接口的方式创建线程，　以Callable+FutureTask的方式创建线程
    17.公平锁与非公平锁的区别
       非公平锁在调用 lock 后，首先就会调用 CAS 进行一次抢锁，如果这个时候恰巧锁没有被占用，那么直接就获取到锁返回了。
       非公平锁在 CAS 失败后，和公平锁一样都会进入到 tryAcquire 方法，在 tryAcquire 方法中，如果发现锁这个时候被释放了（state == 0），非公平锁会直接 CAS 抢锁，但是公平锁会判断等待队列是否有线程处于等待状态，如果有则不去抢锁，乖乖排到后面。
       公平锁和非公平锁就这两点区别，如果这两次 CAS 都不成功，那么后面非公平锁和公平锁是一样的，都要进入到阻塞队列等待唤醒。相对来说，非公平锁会有更好的性能，因为它的吞吐量比较大。当然，非公平锁让获取锁的时间变得更加不确定，可能会导致在阻塞队列中的线程长期处于饥饿状态。
    18.分布式事务：
       TCC:Try、Confirm、Cancel　Try 阶段：对各个服务的资源做检测以及对资源进行锁定。Confirm 阶段：在各个服务中执行实际的操作。Cancel 阶段：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作。 
    
参考链接：
[Java并发编程之异步Future机制的原理和实现](https://blog.csdn.net/lovezhaohaimig/article/details/80344299)
[深度解读 java 线程池设计思想及源码实现](https://javadoop.com/post/java-thread-pool)
[CompletableFuture原理解析](https://www.jianshu.com/p/abfa29c01e1d)
[CountDownLatch和CylicBarrier以及Semaphare你使用过吗](https://www.cnblogs.com/wangsen/p/11170709.html)
[[分布式]：分布式系统的CAP理论](https://blog.csdn.net/w372426096/article/details/80437198)
[分布式事务之TCC](https://www.jianshu.com/p/58911d2e8b28)
[自旋锁、排队自旋锁、MCS锁、CLH锁](https://coderbee.net/index.php/concurrent/20131115/577)
### Spring

- 动态代理

Cglib代理,也叫作子类代理,它是在内存中构建一个子类对象从而实现对目标对象功能的扩展.JDK的动态代理有一个限制,就是使用动态代理的对象必须实现一个或多个接口,如果想代理没有实现接口的类,就可以使用Cglib实现.Cglib是一个强大的高性能的代码生成包,它可以在运行期扩展java类与实现java接口.它广泛的被许多AOP的框架使用,例如Spring AOP和synaop,为他们提供方法的interception(拦截)Cglib包的底层是通过使用一个小而块的字节码处理框架ASM来转换字节码并生成新的类.不鼓励直接使用ASM,因为它要求你必须对JVM内部结构包括class文件的格式和指令集都很熟悉.
jdk动态代理

- IOC

    1.IOC: 容器ApplicationContext虽然继承自BeanFactory的接口，但其内部持有一个BeanFactory实例，用于创建和管理Bean，项目启动后调用其refresh方法进行初始化，生成所有单例模式的Bean。BeanDefinition 中保存了我们的 Bean 信息，比如这个 Bean 指向的是哪个类、是否是单例的、是否懒加载、这个 Bean 依赖了哪些 Bean 等等。首先会根据配置加载BeanDefinition，然后将所以的BeanDefinition存入容器的一个Map中，完成后BeanFactory的初始化完成。随后开始Bean的初始化流程，通过getBean进行加载，已经加载过的会直接返回，加载过程中遇到依赖的Bean会进行递归加载，调用无参构造函数或者构造函数依赖注入进行实例创建，然后对Bean依赖的property进行注入
    2.Spring循换依赖问题：通过三级缓存和提前曝光机制解决。比如Ａ字段中依赖Ｂ，Ｂ字段中依赖Ａ。当Ａ在实例化后（对象初始化的第一步）便曝光到第三级缓存中，属性赋值Ｂ时发现没有B，便初始化Ｂ，在属性赋值Ａ时便可以在第三级缓存中找到Ａ的引用赋值，完成Ｂ的初始化，保存到第一级缓存；之后返回给Ａ完成初始化。
    
参考链接：
[Spring IOC 容器源码分析](https://javadoop.com/post/spring-ioc)
[Spring如何解决循环依赖](https://blog.csdn.net/quliuwuyiz/article/details/79416184)

-　AOP

AOP:　ProxyFatoryBean用于创建代理对象，先初始化Advisor链，然后进行代理类的生成。当代理类执行方法时，会调用invoke方法，invoke方法中对aop拦截器进行检测，如果存在拦截器，则生成MethodInvocation进行拦截链的链式调用。不断得调用procced方法，每次进去后计数器自增，取出下一个拦截其，检查advise与当前的调用是否match,匹配的话将执行该advise    


参考链接：
[Spring AOP 源码解析](https://javadoop.com/post/spring-aop-source)
[剑指Spring源码（三）俯瞰Spring的Bean的生命周期（大众版）](https://www.cnblogs.com/CodeBear/p/10867707.html#4462519)
### Spring Cloud

- Ribbon
　负责均衡客户端基于RestTemplate实现，通过拦截器机制实现负载均衡，在拦截器中拿到请求url中的serviceId，传入LoadBalanceClient进行服务实例的获取,获取时通过ILoadBalance负载均衡器获取服务，服务实例对象封装了ip等信息。利用服务实例初始化serviceRequestWarpper，重写getUri函数将服务id转换为ip，继续进行后续拦截链的链式调用。

参考链接：
[关于RestTemplate 非常推荐的几篇博文（原理剖析）](https://blog.csdn.net/hanhanbubble/article/details/90752591)

### 设计模式

- 代理模式

静态代理：由程序员或特定工具创建代理类，在程序运行前代理类的.class文件已经存在
动态代理：在程序运行时通过反射机制动态创建而成

静态代理类优缺点

优点：

代理使客户端不需要知道实现类是什么，怎么做的，而客户端只需知道代理即可（解耦合），对于如上的客户端代码，newUserManagerImpl()可以应用工厂将它隐藏，如上只是举个例子而已。

缺点：

1）代理类和委托类实现了相同的接口，代理类通过委托类实现了相同的方法。这样就出现了大量的代码重复。如果接口增加一个方法，除了所有实现类需要实现这个方法外，所有代理类也需要实现此方法。增加了代码维护的复杂度。

2）代理对象只服务于一种类型的对象，如果要服务多类型的对象。势必要为每一种对象都进行代理，静态代理在程序规模稍大时就无法胜任了。如上的代码是只为UserManager类的访问提供了代理，但是如果还要为其他类如Department类提供代理的话，就需要我们再次添加代理Department的代理类。

参考链接：
[代理模式](https://www.cnblogs.com/zuoxiaolong/p/pattern3.html)
[JAVA学习篇--静态代理VS动态代理](https://blog.csdn.net/hejingyuan6/article/details/36203505)
[项目中用到的设计模式](https://www.jianshu.com/p/8afd396e314f)
### 数据库

- 引擎对比  
MyISAM拥有较高的插入、查询速度，但不支持事务。MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复
InnoDB是事务型数据库的首选引擎，支持事务安全表（ACID），支持行锁定和外键，InnoDB是默认的MySQL引擎。InnoDB将它的表和索引在一个逻辑表空间中，表空间可以包含数个文件。这与MyISAM表不同，比如在MyISAM表中每个表被存放在分离的文件中。聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键。辅助索引data域存储相应记录主键的值而不是地址。InnoDB还支持外键（FOREIGN KEY）

[MySQL存储引擎MyISAM与InnoDB区别总结整理]()
- 事务

数据库事务的实现原理：
事务每开启一个实例，都会分配一个版本号给它，如果读取的数据行正在被其它事务执行DELETE或UPDATE操作（即该行上有排他锁），这时该事物的读取操作不会等待行上的锁释放，而是根据版本号去读取行的快照数据（记录在undo log中），这样，事务中的查询操作返回的都是同一版本下的数据，解决了不可重复读问题。
原子性和一致性通过Undo log来实现。UndoLog的原理很简单，为了满足事务的原子性，在操作任何数据之前，首先将数据备份到一个地方（这个存储数据备份的地方称为UndoLog）。然后进行数据的修改。如果出现了错误或者用户执行了ROLLBACK语句，系统可以利用Undo Log中的备份将数据恢复到事务开始之前的状态。
RedoLog记录的是新数据的备份。在事务提交前，只要将RedoLog持久化即可，不需要将数据持久化。当系统崩溃时，虽然数据没有持久化，但是RedoLog已经持久化。系统可以根据RedoLog的内容，将所有数据恢复到最新的状态。

脏读：是指一个事务中访问到了另外一个事务未提交的数据。不可重复读是指在一个事务内根据同一个条件对行记录进行多次查询，但是搜出来的结果却不一致。幻读是指同一个事务内多次查询返回的结果集不一样（比如增加了或者减少了行记录）。不同在于不可重复读是同一个记录的数据内容被修改了，幻读是数据行记录变多了或者少了
事务隔离：read uncommitted（读取未提交数据：导致脏读）　read committed（可以读取其他事务提交的数据：导致不可重复读）---大多数数据库默认的隔离级别；repeatable read（可重读：导致幻读）---MySQL默认的隔离级别；serializable（串行化：有事务读的时候其他写会被挂起）

事务特性：原子性　　一致性　数据库总数从一个一致性的状态转换到另一个一致性的状态。　　隔离性　一个事务所做的修改在最终提交以前，对其他事务是不可见的。　持久性　一旦事务提交，则其所做的修改就会永久保存到数据库中。此时即使系统崩溃，修改的数据也不会丢失。
- 索引
数据库索引分类：从数据结构角度　B+树索引　hash索引　FULLTEXT索引（InnoDB引擎5.7以后支持）R-Tree索引　　从物理存储角度　　聚簇索引（一般对主键建立，物理存放顺序与索引顺序是一致的）　非聚簇索引　　聚簇索引中的每个叶子节点包含主键值和余下的列

[和刚入门的菜鸟们聊聊--什么是聚簇索引与非聚簇索引](https://www.cnblogs.com/auxg/p/Cluster-and-NonCluster-index.html)

- Redis
Redis主从同步策略　主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。https://blog.csdn.net/rentuo53/article/details/84912941
Redis的哨兵机制　能监控多个master-slave集群，发现master宕机后能进行自动切换。不时地监控redis是否按照预期良好地运行;如果发现某个redis节点运行出现状况，能够通知另外一个进程；能够进行自动切换（进行主备切换）。当一个master节点不可用时，能够选举出master的多个slave中的一个来作为新的master,其它的slave节点会将它所追随的master的地址改为被提升为master的slave的新地址。使用raft选举算法.
缓存穿透：缓存穿透是指查询一个一定不存在的数据，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了。　　　解决方案：有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空，我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。
缓存雪崩　缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。解决方案：缓存失效时的雪崩效应对底层系统的冲击非常可怕。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。这里分享一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。
缓存击穿　对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。解决方案　使用互斥锁(mutex key)　业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。

- 分布式系统一致性
  XA协议　　第一阶段：事务管理器要求每个涉及到事务的数据库预提交(precommit)此操作，并反映是否可以提交　　第二阶段：事务协调器要求每个数据库提交数据，或者回滚数据。　　优点： 尽量保证了数据的强一致，实现成本较低，缺点:　单点问题:事务管理器如果宕机，资源管理器就会一直阻塞，导致数据库无法使用。　同步阻塞:在准备就绪之后，资源管理器中的资源一直处于阻塞，直到提交完成，释放资源。　数据不一致:两阶段提交协议虽然为分布式数据强一致性所设计，但仍然存在数据不一致性的可能，比如在第二阶段中，假设协调者发出了事务commit的通知，但是因为网络问题该通知仅被一部分参与者所收到并执行了commit操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性。
- 数据库优化

查询优化：面对大规模数据量时，采取SELECT * FROM table WHERE id >= (SELECT id FROM table LIMIT 1000000, 1) LIMIT 10; 对分页查询进行优化，由于查询出id后，会遍历按照id 去外存区table数据　然后丢弃前面的，导致效率低下。
[如何提高MySQL Limit查询的性能](http://www.nowamagic.net/librarys/veda/detail/1900)
[数据库优化方案整理](https://blog.csdn.net/u013628152/article/details/82184809)

参考链接：
[为什么分布式一定要有redis，redis的一些优缺点q](https://blog.csdn.net/hcmony/article/details/80694560)
[数据库本地事务的实现原理](https://blog.csdn.net/qq360694660/article/details/88695365)
[数据库 redo undo log](https://blog.csdn.net/oracle_29/article/details/85717855)
[大白话布隆过滤器](https://www.cnblogs.com/CodeBear/p/10911177.html)
[谈谈数据库，缓存一致性](https://www.cnblogs.com/CodeBear/p/12118050.html#4472208)
[REDIS缓存穿透，缓存击穿，缓存雪崩原因+解决方案](https://www.cnblogs.com/xichji/p/11286443.html)
[一步步分析为什么B+树适合作为索引的结构 以及索引原理 (阿里面试)](https://www.cnblogs.com/aspirant/p/9214485.html)
[面试中关于Redis的问题看这篇就够了](https://blog.csdn.net/qq_34337272/article/details/80012284)
### 网络
- tcp三次握手的本质：交换并确认双方的数据序号。
        1.SYN-SENT --> <SEQ=100><CTL=SYN> --> SYN-RECEIVED ​ 
        2.ESTABLISHED <-- <SEQ=300><ACK=101><CTL=SYN,ACK> <-- SYN-RECEIVED ​ 
        3.ESTABLISHED --> <SEQ=101><ACK=301><CTL=ACK> --> ESTABLISHED
        四次挥手，每一端的关闭请求都需要被确认一次：2（client, server）*2(FIN, ACK)　服务器主动关闭链接的话会只有两次挥手　后续会回复客户端RST
        
        TIME_WAIT的产生条件：主动关闭方在发送四次挥手的最后一个ACK（第四次挥手后不会立刻关闭）会变为TIME_WAIT状态，保留次状态的时间为两个MSL（linux里一个MSL为30s，是不可配置的）
        TIME_WAIT两个MSL的作用：可靠安全的关闭TCP连接。比如网络拥塞，主动方最后一个ACK被动方没收到，这时被动方会对FIN开启TCP重传，发
        送多个FIN包，在这时尚未关闭的TIME_WAIT就会把这些尾巴问题处理掉，不至于对新连接及其它服务产生影响。
        TIME_WAIT占用的资源：少量内存（查资料大概4K）和一个fd。
        TIME_WAIT关闭的危害：1、  网络情况不好时，如果主动方无TIME_WAIT等待，关闭前个连接后，主动方与被动方又建立起新的TCP连接，这时被
        动方重传或延时过来的FIN包过来后会直接影响新的TCP连接；2、  同样网络情况不好并且无TIME_WAIT等待，关闭连接后无新连接，当接收到被动
        方重传或延迟的FIN包后，会给被动方回一个RST包，可能会影响被动方其它的服务连接。
        TIME_WAIT过多的解决办法： net.ipv4.tcp_tw_recycle=1  　表示开启TCP连接中TIME-WAIT sockets的快速回收
- Reactor模式
    　一种比较流行的做法是服务端监听线程和 IO 线程分离，类似于 Reactor 的多线程模型。bossGrouＰ线程组实际就是 Acceptor 线程池，负责处理客户端的 TCP 连接请求，workerGroup 是真正负责 I/O 读写操作的线程组
    
- TCP确保可靠性的机制　校验和　序列号　确认应答　超时重传　连接管理（三次握手　四次挥手）　
  流量控制　在TCP协议的报头信息当中，有窗口大小，即接收端接收数据缓冲区的剩余大小。接收端会在确认应答发送ACK报文时，将自己的即时窗口大小填入，并跟随ACK报文一起发送过去。而发送方根据ACK报文里的窗口大小的值的改变进而改变自己的发送速度。如果接收到窗口大小的值为0，那么发送方将停止发送数据。并定期的向接收端发送窗口探测数据段，让接收端把窗口大小告诉发送端。
  拥塞控制　 快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认
  RST标志位表示强制断开链接
  sack selective acknowledgment，也就是选择性确认，添加sack功能需要在TCP包头加两个选项，一个是开启选项（enabling optiocookie 一般由服务器生成，可设置失效时间。如果在浏览器端生成Cookie，默认是关闭浏览器后失效,存放数据大小一般4K左右，而sessionStorage与localStorage大小在5兆左右，在客户端生成，localStorage除非被清除，否则会永久保存，sessionStorage仅在当前会话下有效，关闭页面或浏览器后被清除，cookie在与服务器端通信每次都会携带在HTTP头中，如果使用cookie保存过多数据会带来性能问题,而sessionStorage与localStorage仅在客户端（即浏览器）中保存，不参与和服务器的通信。n），另一个是sack选项（sack option）本身。开启sack选项后，receiver会将自己收到了哪些包，没收到哪些包的信息记录在sack段中告诉给sender，这样sender便可以一次性重传所有的丢包。
  MSS : Maximum Segment Size最大分段大小
- 状态码:
  100（Continue）客户端应该继续它的请求。这个过渡的响应用于告知客户端，请求的初始部分已经被服务器收到，并且没有被服务器拒绝。客户端应该继续发送剩余的请求，如果请求已经完成，就忽略这个响应。服务器必须在请求完成后发送一个最终的响应。
  206状态码（Partial Content）服务器已经成功处理了部分GET请求。类似于FlashGet或者迅雷这类的HTTP 下载工具都是使用此类响应实现断点续传或者将一个大文档分解为多个下载段同时下载。
  304 表明了客户端中所请求资源的缓存仍然是有效的,也就是说该资源从上次缓存到现在并没有被修改过.条件请求可以在确保客户端的资源是最新的同时避免因每次都请求完整资源给服务器带来的性能问题.
  301 redirect: 301 代表永久性转移(Permanently Moved) 302 redirect: 302 代表暂时性转移(Temporarily Moved )
- EPoll两种工作模式
    ET:当有事件发生时，系统只会通知你一次，即在调用epoll_wait返回fd后，不管这个事件你处理还是没处理，处理完没有处理完，当再次调用epoll_wait时，都不会再返回该fd　LT:使用LT模式意味着只要fd处于可读或者可写状态，每次epoll_wait都会返回该fd，这样的话会带来很大的系统开销，且处理时候每次都需要把这些fd轮询一遍，如果fd的数量巨大，不管有没有事件发生，epoll_wait都会触发这些fd的轮询判断。
- TCP报文段是面向字节流的，UDP包是面向数据报的
    面向报文的传输方式是应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。因此，应用程序必须选择合适大小的报文。若报文太长，则IP层需要分片，降低效率。若太短，会是IP太小。UDP对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。这也就是说，应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序看成是一连串的无结构的字节流。TCP有一个缓冲，当应用程序传送的数据块太长，TCP就可以把它划分短一些再传送。如果应用程序一次只发送一个字节，TCP也可以等待积累有足够多的字节后再构成报文段发送出去。在TCP建立连接前两次握手的SYN报文中选项字段的MSS值，通信双方商定通信的最大报文长度。如果应用层交付下来的数据过大，就会对数据分段，然后发送；否则通过滑动窗口协议来控制通信双发的数据。
    tcp传输对准确性要求高速度相对可以慢，因此用于HTTP,FTP，邮件传输，远程连接；udp用于即时通讯延迟低，准确性低，网络电话，语音通信
- netty的零拷贝
    将内存空间分段的字节数组在逻辑上整合为一个整体的字节数组（段式内存思想，将逻辑index变成分块编号和段内偏移）
参考链接：
[Reactor三种线程模型与Netty线程模型](https://www.cnblogs.com/lvyahui/p/9030232.html)    
[TCP 和 UDP 的区别](https://blog.csdn.net/zhang6223284/article/details/81414149)
[TCP-IP详解：SACK选项（Selective Acknowledgment）](https://blog.csdn.net/wdscq1234/article/details/52503315?locationNum=3)
### 场景问题
[架构师手把手教你如何设计一个秒杀系统？](https://www.jianshu.com/p/729f1f0f6e18)
[如何设计一个秒杀系统](https://blog.csdn.net/mulinsen77/article/details/89054063)
[检查 1亿的手机号码以进行重复](https://kb.kutu66.com/algorithm/post_1011410  )
[如何在有限的内存限制下实现数十亿级手机号码去重](https://www.jianshu.com/p/b39eb55d4670)